---
title: "Auth0のEvent StreamとAWS EventBridgeを連携して、リトライ可能かつ非同期に情報を連携する"
emoji: "😎"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Auth0", "AWS", "EventBridge", "SQS", "Lambda"]
published: false
---
# Auth0のEvent StreamとAWSのEventBridgeを連携して、リトライ可能かつ非同期に情報を連携する

## 1. はじめに

### 1.1 この記事で実現すること

この記事では、Auth0でユーザーをブロックした際に、自作アプリケーション側にもブロック状態が自動的に反映される仕組みを構築します。
具体的には、Auth0の管理画面でユーザーをブロックすると、その情報がAWS EventBridge経由でアプリケーションに通知され、即座にブロック状態が反映されます。

前回の記事では、Webhookを使った実装を紹介しましたが、今回はAWSのマネージドサービスを活用することで、より堅牢で運用しやすい構成を実現します。

### 1.2 この記事のアプローチ

今回の実装では、Auth0のEvent StreamとAWS EventBridgeを連携させることで、非同期かつリトライ可能な構成を実現します。
前回のWebhook版との大きな違いは、AWSのマネージドサービス（EventBridge、SQS、Lambda）を活用することで、リトライ機構やDLQ（Dead Letter Queue）による失敗イベントの再処理が可能になる点です。

これにより、一時的なネットワーク障害やアプリケーション側のエラーが発生しても、イベントを取りこぼすことなく確実に処理できるようになります。

### 1.3 前回記事との関係

前回の記事では、Auth0のEvent StreamからWebhookで直接通知を受け取る構成を紹介しました。
https://zenn.dev/maronn/articles/notify-block-user-by-auth0-event-stream

Webhook版はシンプルで実装しやすい反面、以下のような課題がありました。

- エラーが発生した際のリトライ処理を自前で実装する必要がある
- サーバーレス環境（Cloudflare Workersなど）では、EventEmitterなどでイベントが消失するリスクがある
- 連携先の長時間障害には対応しづらい

今回のEventBridge版では、これらの課題をAWSのマネージドサービスで解決し、より本番運用に適した構成を目指します。

## 2. 全体構成

### 2.1 構成図

今回構築するシステムの全体構成は以下のようになります。

![構成図（準備中）](/images/auth0-and-eventbridge-integrate/architecture.png)

Auth0からAWSのEventBridge、そしてデモアプリケーションまでの一連の流れを図示しています。
各コンポーネントの詳細な役割については、この後の項で説明します。

### 2.2 処理フローの説明

システム全体の処理フローを順を追って説明します。

1. **Auth0：ユーザーブロックイベントが発生**
   Auth0の管理画面でユーザーをブロックすると、`user.updated`イベントが発生します。

2. **EventBridge：Auth0からのイベントを受信**
   Auth0のEvent Streamで設定したAWS EventBridgeに、パートナーイベントソース経由でイベントが送信されます。

3. **EventBus：イベントのフィルタリングとルーティング**
   EventBusに設定したルールで、Auth0からのイベントのみをフィルタリングし、SQSへ転送します。

4. **SQS：イベントのキューイング**
   イベントをキューに保持し、後続のLambdaで処理できるようにします。
   処理に失敗した場合は、設定した回数リトライした後、DLQ（Dead Letter Queue）に退避されます。

5. **Lambda：イベント処理とアプリへの通知**
   SQSからイベントを取得し、デモアプリケーションのAPIを呼び出してブロック情報を通知します。

6. **Demo App：ブロック状態の反映**
   今回のデモでは、Cloudflare Workers上で動作するVike/Honoアプリケーションでブロック状態を受け取り、反映します。

この構成により、Auth0でユーザーをブロックした瞬間から、アプリケーション側でもブロック状態が反映されるまでの流れが、非同期かつ確実に実行されます。

### 2.3 各コンポーネントの役割

システムを構成する各コンポーネントの役割を整理します。

**EventBridge + EventBus**
Auth0からのイベントを受信し、適切なターゲット（この場合はSQS）にルーティングします。
パートナーイベントソースを使用することで、Auth0との連携が安全に行えます。

**SQS（Simple Queue Service）**
イベントをキューに保持し、非同期処理を実現します。
バッファリング機能により、Lambda側の処理速度に関係なく、イベントを確実に受け取ることができます。
また、visibility timeoutの設定により、処理中のメッセージが他のコンシューマーに配信されないようにします。

**DLQ（Dead Letter Queue）**
SQSでの処理に失敗したイベントを退避します。
連携先のアプリケーションが復旧した後に、DLQからメッセージを再度メインキューに戻すことで、失敗したイベントを再処理できます。
これにより、一時的な障害でイベントが失われることを防ぎます。

**Lambda（Node.js）**
SQSからイベントを取得し、デモアプリケーションのAPIエンドポイントにHTTPリクエストを送信します。
今回はNode.js 20を使用し、シンプルなHTTPクライアント処理を実装します。

## 3. Event Streamとは

### 3.1 概要

Auth0のEvent Streamは、Auth0で発生した各種イベントをリアルタイムに外部システムへ配信する機能です。
記事執筆時点では[Early Access](https://auth0.com/docs/customize/events/create-an-event-stream#:~:text=an%20Event%20Stream-,Events%20are%20currently%20available%20in,.,-To%20learn%20more)の機能となっていますので、今後仕様が変更される可能性があることを念頭に置いてください。

Event Streamを使用することで、ユーザーに関するイベント（ログイン、ユーザー情報の更新、ブロックなど）や組織（Organization）に関するイベントを検知し、外部システムに配信できます。

今回使用する`user.updated`イベントは、ユーザー情報が更新された際に発行されます。
イベントペイロードには、user_id、blocked、emailなどの情報が含まれており、このblockedプロパティを確認することで、ユーザーがブロックされたかどうかを判定できます。

ただし、注意点として、user.updatedイベントはブロック以外の更新でも発火します。
例えば、メールアドレスの変更やメタデータの更新などでも同じイベントが配信されるため、本来であればblockedプロパティの変化を検知するフィルタリングロジックが必要になります。

### 3.2 配信先の選択肢

Auth0のEvent Streamは、複数の配信先をサポートしています。

**Webhook URL**
前回の記事で使用した方式です。
指定したURLに対して、HTTP POSTリクエストでイベントを送信します。
実装がシンプルで、任意のエンドポイントに配信できるメリットがありますが、リトライ処理や障害対応を自前で実装する必要があります。

**AWS EventBridge**
今回使用する方式です。
AWSのパートナーイベントソースを経由して、EventBridgeにイベントを配信します。
AWSのマネージドサービスと連携できるため、リトライ機構やDLQなどの機能を活用でき、より堅牢な構成を実現できます。

その他にも、Azure Event GridやDatadogなどへの配信も可能です。
今回は、AWSのマネージドサービスと連携しやすいEventBridgeを使用します。

### 3.3 参考ドキュメント

Auth0のEvent Streamに関する詳細は、公式ドキュメントを参照してください。
https://auth0.com/docs/customize/events

また、Event StreamとAWS EventBridgeの連携については、以下のドキュメントが参考になります。
https://auth0.com/docs/ja-jp/customize/events/create-an-event-stream#aws-eventbridge

## 4. 今回の構成の利点

### 4.1 非同期処理によるブロッキングの回避

今回の構成では、Auth0からEventBridge、SQS、Lambdaと非同期に処理が進むため、イベント発生元であるAuth0の処理をブロックしません。

前回のWebhook版でも、受け取った後に非同期処理を行うことは可能ですが、別途キューの仕組みを用意する必要があります。
特に、サーバーレス環境（例：Cloudflare Workers）でWebhookを受ける場合、EventEmitterなどを使ったイベント駆動の実装では、イベントが消失するリスクがあります。

Cloudflare Workersのようなエッジ環境では、リクエストのライフサイクルが短く、バックグラウンド処理の保証が難しいため、確実にイベントを処理するにはキューイングの仕組みが必要です。

今回のEventBridge + SQS構成では、AWSのマネージドサービスがキューイングを担保してくれるため、こうした課題を気にする必要がありません。

### 4.2 リトライ機構による一時的障害への耐性

SQSには標準的なリトライ機能が組み込まれており、Lambda関数での処理が失敗した場合、自動的にリトライされます。
今回の構成では、maxReceiveCountを3回に設定しているため、3回失敗するとDLQに移動します。

前回のWebhook版では、エラーが発生した際に処理が消失してしまう可能性がありました。
Webhook側でリトライ処理を実装することも可能ですが、連携先のアプリケーションが長時間ダウンしている場合、何度リトライしても失敗し続けることになります。

SQSを使用することで、メッセージはキューに保持され、連携先が復旧するまで待つことができます。
また、visibility timeoutの設定により、処理中のメッセージが重複して処理されることも防げます。

### 4.3 DLQによる失敗イベントの再処理

DLQ（Dead Letter Queue）は、指定した回数リトライしても処理に失敗したメッセージを退避する仕組みです。

連携先のアプリケーションに長時間障害が発生した場合、メインキューでリトライを繰り返すのではなく、DLQに退避させることで、他の正常なメッセージの処理を妨げません。

そして、連携先が復旧した後に、DLQからメッセージを再度メインキューに戻すことで、失敗したイベントを再処理できます。
この再投入は、手動で行うことも、Lambda関数を使って自動化することも可能です。

これにより、一時的な障害でイベントが失われることを防ぎ、確実にイベントを処理できるようになります。

## 5. 今回の構成の注意点

### 5.1 イベント順序の担保の難しさ

今回の構成では、標準のSQSキュー（FIFOではない）を使用しているため、イベントの処理順序は保証されません。

例えば、以下のような状況が考えられます。

1. ユーザーAをブロックするイベントが発生
2. その直後にユーザーAのブロックを解除するイベントが発生
3. 何らかの理由でブロックイベントの処理が失敗し、DLQに移動
4. ブロック解除イベントは正常に処理される
5. 後でDLQからブロックイベントが再処理される

この場合、実際にはブロックが解除されているにもかかわらず、最後にブロックイベントが処理されるため、ユーザーAはブロック状態になってしまいます。

FIFOキューを使用すれば、ある程度の順序は保証されますが、DLQとメインキューを合わせた順序担保は困難です。
この問題を完全に解決するには、アプリケーション側でタイムスタンプを使った制御や、イベントのバージョニングなどの工夫が必要になります。

今回のデモでは、この点については対応していませんが、本番運用では考慮が必要な点です。

### 5.2 冪等性の確保が必要

SQSとLambdaの構成では、同じイベントが複数回処理される可能性があります。

例えば、以下のような状況が考えられます。

- Lambda関数がSQSからメッセージを取得し、処理を開始
- 処理自体は成功したが、メッセージの削除前にLambda関数がタイムアウト
- SQSはメッセージが削除されていないため、再度同じメッセージを配信

このような重複処理を防ぐには、アプリケーション側で冪等性を担保する必要があります。
具体的には、イベントに含まれるevent_idをキーにして、既に処理済みかどうかをチェックする仕組みが有効です。

今回のデモでは、シンプルさを優先して冪等性は担保していませんが、本番運用では必須の対策となります。

### 5.3 SQS/Lambdaの設定値

今回の構成では、以下の設定値を使用しています。

- **visibility_timeout_seconds: 90秒**
  メッセージが処理中に他のコンシューマーに配信されないようにする時間です。
  Lambda関数のタイムアウト（30秒）よりも長く設定することで、処理中のメッセージが重複して配信されることを防ぎます。

- **maxReceiveCount: 3回**
  メッセージが取得された回数がこの値を超えると、DLQに移動します。
  今回は3回失敗した場合にDLQに移動するように設定しています。

- **Lambda側のリトライ: 3回**
  Lambda関数でエラーが発生した場合、SQSが自動的にリトライします。

これらの値については、深い検討を行ったわけではなく、あくまで参考値として記載しています。
本番運用では、アプリケーションの特性に応じて適切な値を設定してください。

### 5.4 コストへの意識

今回の記事では、詳細なコスト計算は行いませんが、EventBridge、SQS、Lambdaのそれぞれでコストが発生します。

特に、EventBridgeはイベント数に応じて課金されるため、むやみに多くのイベントを流すとコストが増加します。
前述の通り、user.updatedイベントはブロック以外の更新でも発火するため、フィルタリングを行わないと不要なイベントも配信されてしまいます。

本番導入時は、以下の点を考慮してコストを見積もることを推奨します。

- 月間のイベント発生数
- SQSのメッセージ数とリトライ回数
- Lambda関数の実行回数と実行時間

AWSの料金計算ツールを使用することで、おおよそのコストを事前に把握できます。

## 6. 設定手順

### 6.1 前提条件

今回の構成を試すには、以下の前提条件が必要です。

- **Cloudflareアカウント**
  デモアプリケーションをCloudflare Workers上にデプロイします。
  無料プランで構いません。

- **Auth0テナント**
  Auth0のアカウントとテナントが作成済みであること。
  Event Streamを使用するため、Early Access機能が利用できる必要があります。

- **AWSアカウント**
  EventBridge、SQS、Lambdaを使用します。
  IAM Identity CenterでAdmin権限を持つSSOアカウントがあることを前提としています。

これらのアカウントが準備できていれば、サンプルリポジトリの手順に従って構築を進められます。

### 6.2 サンプルリポジトリ

今回の構成を実際に試すためのサンプルコードは、以下のGitHubリポジトリで公開しています。

（サンプルリポジトリのリンク：準備中）

READMEには、詳細なセットアップ手順を記載していますので、そちらを参照してください。
このブログでは、設定の流れの概要のみを説明します。

### 6.3 設定の流れ（概要のみ）

サンプルリポジトリを使った設定の流れは、以下のようになります。

**1. AWSのSSOとAuth0のTerraform用アプリケーションをCLI経由で設定**
まず、TerraformでAWSリソースを管理するための準備を行います。
AWS CLIでSSOログインを行い、Terraform用のクレデンシャルを取得します。
また、Auth0側でもTerraformを使うため、Management APIにアクセスできるMachine to Machine Applicationを作成します。

**2. Auth0側でEvent StreamをTerraform経由で生成**
Auth0のEvent Streamを、Terraformを使って作成します。
この際、AWSアカウントIDとリージョンを指定することで、AWSのパートナーイベントソースと連携します。

**3. AWS側でパートナーイベントソースの紐づけをCLIで行う**
Auth0がAWS側に作成したパートナーイベントソースを、EventBusに関連付けます。
この手順は、TerraformではできないためCLIスクリプトで実行します。

**4. Terraform経由でAWSの残りの構成（EventBus、SQS、DLQ、Lambda）を設定**
EventBusのルール、SQS、DLQ、Lambda関数をTerraformで作成します。
パートナーイベントソースから作成されたEventBusをデータソースとして参照し、ルールを設定します。

**5. デモアプリ用のAuth0アプリ作成とデモアプリのデプロイをCLIで行う**
最後に、デモアプリケーションをCloudflare Workersにデプロイし、Auth0でアプリケーションを登録します。

以上で、Auth0からAWS EventBridge経由でデモアプリケーションにイベントが配信される環境が構築できます。

## 7. 個人的にハマったポイント

### 7.1 Auth0のEventBridge設定とAWSの紐づけ

今回の構成を構築する際に、最も理解に時間がかかったのが、Auth0とAWSの連携方法です。

Auth0のEvent Stream作成画面では、AWSアカウントIDとリージョンを入力するだけで、特にAPIキーやシークレットを設定する項目はありません。
最初は「これだけでAWSとどう連携するのか？」と疑問に思いました。

![Auth0のEvent Stream設定画面（準備中）](/images/auth0-and-eventbridge-integrate/auth0-eventbridge-setting.png)

答えは、**AWSのパートナーイベントソース**にありました。

Auth0がEvent Streamを作成すると、AWS側に自動的にパートナーイベントソースが作成されます。
このパートナーイベントソースは、AWSのEventBridgeコンソールで確認でき、`aws.partner/auth0.com/...`のような名前で表示されます。

そして、このパートナーイベントソースを、AWS側でEventBusに関連付ける必要があります。
この関連付けを行うことで、Auth0からのイベントがEventBusに配信されるようになります。

この仕組みを理解するのに、以下の記事がとても参考になりました。
https://dev.classmethod.jp/articles/auth0-log-streams-to-amazon-eventbridge-with-cloudformation/

### 7.2 パートナーイベントソースとTerraformの連携

もう一つハマったのが、パートナーイベントソースとTerraformの連携方法です。

パートナーイベントソースをEventBusに関連付ける操作は、**Terraformでは実行できません**。
これは、パートナーイベントソースがAWS外部（この場合はAuth0）によって作成されるため、Terraformで管理できないためです。

そのため、この関連付けは以下のいずれかの方法で行う必要があります。

1. AWSコンソールのUI上で手動で関連付ける
2. AWS CLIを使ってスクリプトで実行する

サンプルリポジトリでは、以下のようなCLIスクリプトで対応しています。

```bash
#!/bin/bash
# パートナーイベントソースを取得
EVENT_SOURCE_NAME=$(aws events list-event-sources \
  --name-prefix "aws.partner/auth0.com" \
  --query 'EventSources[0].Name' \
  --output text)

# EventBusに関連付ける
aws events activate-event-source \
  --name "$EVENT_SOURCE_NAME"
```

一方、関連付けた後のEventBusは、Terraformの`aws_cloudwatch_event_bus`データソースで参照できます。
これにより、EventBusに対するルールやターゲット（SQSなど）の設定をTerraformで管理できます。

```hcl
# パートナーイベントソースから作成されたEventBusを参照
data "aws_cloudwatch_event_bus" "auth0" {
  name = "aws.partner/auth0.com/..."
}

# EventBusに対するルールを作成
resource "aws_cloudwatch_event_rule" "auth0_events" {
  name           = "auth0-user-events"
  event_bus_name = data.aws_cloudwatch_event_bus.auth0.name

  event_pattern = jsonencode({
    source = ["aws.partner/auth0.com"]
  })
}
```

注意点として、データソースで参照しているため、`terraform destroy`を実行してもパートナーイベントソースの登録は解除されません。
完全にクリーンアップするには、AWS CLIまたはコンソールで手動で削除する必要があります。

### 7.3 詳細な解消方法

これらのハマりポイントの詳細な解消方法は、サンプルリポジトリのREADMEとスクリプトに記載しています。
特に、パートナーイベントソースの関連付けスクリプトは、`scripts/activate-partner-event-source.sh`を参照してください。

（サンプルリポジトリへのリンク：準備中）

## 8. WebhookとEventBridge、どちらを選ぶか

### 8.1 基本的な推奨

前回の記事ではWebhook方式、今回はEventBridge方式を紹介しましたが、どちらを選ぶべきでしょうか。

結論から言うと、**コストが許すならEventBridge（AWS連携）を推奨します**。

ただし、環境や要件によっては、Webhookの方が適している場合もあります。
それぞれのメリット・デメリットを整理して、適切な選択ができるように解説します。

### 8.2 EventBridgeを推奨する理由

EventBridge方式には、以下のようなメリットがあります。

**セキュリティ面での優位性**
Webhook方式では、トークン管理やリクエストの検証を自前で実装する必要があります。
前回の記事では、Bearerトークンを使った認証を実装しましたが、トークンのローテーションや漏洩時の対応など、セキュリティ面での考慮事項が多くなります。

一方、EventBridge方式では、AWSのパートナーイベントソースという仕組みを使うことで、Auth0とAWSの間の連携はAWSのマネージドな仕組みで保護されます。
開発者が認証トークンを管理する必要がなく、セキュリティリスクを軽減できます。

**リトライ設計のしやすさ**
EventBridge + SQS + Lambdaの構成では、AWSのマネージドサービスが提供するリトライ機能をそのまま活用できます。
SQSのvisibility timeout、maxReceiveCount、DLQなど、設定ファイルで簡単にリトライ戦略を調整できます。

Webhook方式で同等の機能を実現しようとすると、キューイングの仕組みを自前で実装する必要があります。

**拡張性**
EventBridgeを使うことで、複数のターゲットにイベントを配信することが容易になります。
例えば、SQS + Lambdaだけでなく、SNSやStep Functionsなど、他のAWSサービスとも連携できます。

また、EventBridgeのフィルタリング機能を使うことで、特定のイベントだけを特定のターゲットに配信するといった柔軟な設計が可能です。

### 8.3 Webhookを選ぶケース

一方、以下のような場合は、Webhook方式の方が適していることもあります。

**AWSを使っていない環境**
EventBridge方式は、AWSのサービスを前提としています。
GCPやAzure、オンプレミス環境で動作するアプリケーションに通知したい場合は、Webhookの方がシンプルです。

**コストを最小限に抑えたい場合**
Webhook方式は、受け取り側のサーバーがあれば追加のコストはほとんどかかりません。
一方、EventBridge方式では、EventBridge、SQS、Lambdaのそれぞれでコストが発生します。

特に、イベント数が多い場合は、EventBridgeの課金が無視できない金額になる可能性があります。
小規模なプロジェクトや、イベント数が少ない場合は、Webhookの方がコスト効率が良いでしょう。

**シンプルさを優先したい場合**
Webhook方式は、HTTPエンドポイントを用意するだけで実装できるため、学習コストが低く、シンプルです。
AWSの知識がないチームや、プロトタイプを素早く作りたい場合は、Webhookの方が適しています。

以上を踏まえて、プロジェクトの要件や環境に応じて、適切な方式を選択してください。

## 9. 終わりに

### 9.1 まとめ

今回は、Auth0のEvent StreamとAWS EventBridgeを連携して、非同期かつリトライ可能な構成を実現する方法を紹介しました。

前回のWebhook版と比較して、以下のようなメリットがあります。

- **非同期処理**: Auth0の処理をブロックせず、AWSのマネージドサービスで確実にイベントを処理
- **リトライ機構**: SQSの標準機能で一時的な障害に対応
- **DLQによる失敗イベントの再処理**: 長時間障害が発生しても、イベントを失わずに再処理可能
- **セキュリティ**: パートナーイベントソースによる安全な連携

一方で、イベント順序の担保や冪等性の確保など、考慮すべき点もあります。
本番運用では、これらの点を踏まえた設計が必要です。

### 9.2 今後の発展

今回の構成をさらに発展させるためのアイデアをいくつか紹介します。

**冪等性の担保**
event_idをキーにして、既に処理済みかどうかをチェックする仕組みを実装することで、重複処理を防げます。
DynamoDBやRedisなどを使って、処理済みイベントのIDを記録しておくと良いでしょう。

**他のイベント種別への拡張**
今回はuser.updatedイベントのみを扱いましたが、Auth0のEvent Streamは様々なイベントをサポートしています。
例えば、ログインイベント（login.success）や組織の変更イベントなども配信できます。
EventBridgeのフィルタリング機能を使って、イベント種別ごとに異なるターゲットに配信することも可能です。

**モニタリング・アラートの追加**
CloudWatch Metricsを使って、SQSのメッセージ数やDLQのメッセージ数を監視し、異常値を検知したらアラートを発報する仕組みを追加すると、運用の安心感が増します。
特に、DLQにメッセージが溜まり続けている場合は、連携先のアプリケーションに問題がある可能性が高いため、早期に検知できるようにしておくことが重要です。

**FIFOキューの検討**
イベントの順序が重要な場合は、標準キューではなくFIFOキューを使用することも検討できます。
ただし、DLQとの組み合わせでは順序保証が難しい点に注意が必要です。

### 9.3 参考リンク

今回の記事で使用したリソースや参考情報をまとめます。

**サンプルリポジトリ**
（準備中）

**Auth0 Event Stream公式ドキュメント**
https://auth0.com/docs/customize/events

**Auth0とAWS EventBridgeの連携**
https://auth0.com/docs/ja-jp/customize/events/create-an-event-stream#aws-eventbridge

**前回記事（Webhook版）**
https://zenn.dev/maronn/articles/notify-block-user-by-auth0-event-stream

**参考にした記事**
https://dev.classmethod.jp/articles/auth0-log-streams-to-amazon-eventbridge-with-cloudformation/

今回の構成は、Auth0のEvent Streamを活用した実践的な例の一つです。
AWSのマネージドサービスを活用することで、堅牢で運用しやすいシステムを構築できました。

ぜひ、皆さんのプロジェクトでも試してみてください。
そして、何か改善点や質問があれば、コメントで教えていただけると嬉しいです。

ここまで読んでいただき、ありがとうございました。